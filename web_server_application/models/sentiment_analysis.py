import dotenv, os
import torch, py_vncorenlp
from transformers import RobertaForSequenceClassification, AutoTokenizer

dotenv.load_dotenv()

# Singleton class
class Singleton(type):
    _instances = {}

    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)
        return cls._instances[cls]


# Implement Singleton b·∫±ng c√°ch d√πng metaclass
class SentimentAnalysis(metaclass=Singleton):
    def __init__(self):
        self.segmenter = py_vncorenlp.VnCoreNLP(annotators=["wseg"], save_dir=os.getenv('VN_CORE_NLP_PATH'))
        self.model = RobertaForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment")
        self.tokenizer = AutoTokenizer.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", use_fast=False)

    def __pre_processing_data(self, sentence):
        output = self.segmenter.word_segment(sentence)  # X·ª≠ l√Ω vƒÉn b·∫£n
        # Join c√°c t·ª´ trong list ƒë·ªÉ merge l·∫°i
        return ''.join([word for word in output])

    def __perform_model(self, input_data):
        # T·∫£i model
        # Khai b√°o option cache_dir d√πng ƒë·ªÉ l∆∞u model v√†o th∆∞ m·ª•c ch·ªâ ƒë·ªãnh (N·∫∑ng 500mb ü•≤üòÉ). N·∫øu kh√¥ng th√¨ s·∫Ω l∆∞u v√†o cache
        # model = RobertaForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", cache_dir='model/model_sa_phobert')
        # model = RobertaForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment")

        # T·∫£i tokenizer (Xem BERT)
        # tokenizer = AutoTokenizer.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", use_fast=False)

        #Ti·ªÅn x·ª≠ l√Ω
        sentence = self.__pre_processing_data(input_data['sentence'])
        # Tokenize sentence v√† chuy·ªÉn th√†nh tensor
        input_ids = torch.tensor([self.tokenizer.encode(sentence)])

        # Ti·∫øn h√†nh tri·ªÉn khai model v·ªõi input
        with torch.no_grad():
            out = self.model(input_ids)
            # T√≠nh softmax ƒë·ªÉ ph√¢n lo·∫°i v√† in k·∫øt qu·∫£ c√≥ d·∫°ng [[NEG, POS, NEU]]
            sentiment_result = out.logits.softmax(dim=-1).tolist()
            print(sentiment_result)
            processed_label = rating_sentiment(sentiment_result)
            return {'label': processed_label, 'sentence': input_data['sentence']}

    def perform_sentiment_analysis(self, input_data):
        # N·∫øu kh√¥ng c√≥ sentence
        if input_data['sentence'] is 'None': return None
        # N·∫øu ƒë√£ c√≥ sentiment v√† sentence (Kh√¥ng c·∫ßn th·ª±c hi·ªán n·ªØa)
        if input_data['sentiment'] != 'None' and input_data['sentence'] != 'None': return input_data
        return self.__perform_model(input_data)


def rating_sentiment(sentiment_result, delta=0.15):
    sentiment_output = sentiment_result[0]
    label = ['NEG', 'POS', 'NEU']

    # G√°n nh√£n v·ªõi t·ª´ng t·ªâ l·ªá xu·∫•t hi·ªán c·ªßa t·ª´ng lo·∫°i c·∫£m x√∫c
    sentiment_rating = [{'label': x, 'rate': sentiment_output[label.index(x)] / sum(sentiment_output)} for x in label]
    sentiment_rating.sort(key=lambda x: x['rate'], reverse=True)

    max_rating = sentiment_rating[0]
    mid_rating = sentiment_rating[1]

    if abs(max_rating['rate'] - mid_rating['rate']) > delta:
        return 'NEU' if max_rating['label'] == 'NEU' else max_rating['label']
    else:
        if max_rating['label'] != 'NEU' and mid_rating['label'] != 'NEU':
            return 'NEU'
        else:
            return max_rating['label']
    # return max(sentiment_rating, key=lambda x: x['rate'])['label']

# Test model
# if __name__ == '__main__':
#     examples = [
#         {'sentiment': None, 'sentence': 'Nh√† n√†y c≈©ng ƒë·∫πp nh∆∞ng t√¥i kh√¥ng th√≠ch n√≥ l·∫Øm'},
#         {'sentiment': 'NEG', 'sentence': 'Ch·ªó n√†y th·∫≠t r√°c r∆∞·ªüi'},
#         {'sentiment': None, 'sentence': 'D·ªãch v·ª• xung quanh r·∫•t ·ªïn v√† t√¥i c·ª±c k√¨ th√≠ch n√≥'},
#         {'sentiment': 'POS', 'sentence': 'Nh√† n√†y c≈©ng ƒë·∫πp nh∆∞ng t√¥i kh√¥ng th√≠ch n√≥ l·∫Øm'},
#         {'sentiment': None, 'sentence': 'B·ªØa s√°ng h∆°i d·ªü nh∆∞ng ch·∫•t l∆∞·ª£ng ph√≤ng x·ªãn l·∫Øm'},
#         {'sentiment': None, 'sentence': 'Netflix h·∫øt h·∫°n s·ª≠ d·ª•ng n√™n t√¥i kh√¥ng th·ªÉ xem phim ƒë∆∞·ª£c'},
#     ]
#     sentiment_analysis = SentimentAnalysis()
#     for example in examples:
#         result = sentiment_analysis.perform_sentiment_analysis(example)
#         print(result.keys())
#         # print("\n")

# def pre_processing_data(sentence):
#     # Load VnCoreNLP
#     segmenter = py_vncorenlp.VnCoreNLP(annotators=["wseg"], save_dir=os.getenv('VN_CORE_NLP_PATH'))
#     output = segmenter.word_segment(sentence)  # X·ª≠ l√Ω vƒÉn b·∫£n
#     # Join c√°c t·ª´ trong list ƒë·ªÉ merge l·∫°i
#     return ''.join([word for word in output])
#
#
# def perform_model(sentence):
#     # T·∫£i model
#     # Khai b√°o option cache_dir d√πng ƒë·ªÉ l∆∞u model v√†o th∆∞ m·ª•c ch·ªâ ƒë·ªãnh (N·∫∑ng 500mb ü•≤üòÉ). N·∫øu kh√¥ng th√¨ s·∫Ω l∆∞u v√†o cache
#     # model = RobertaForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", cache_dir='model/model_sa_phobert')
#
#     model = RobertaForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment")
#
#     # T·∫£i tokenizer (Xem BERT)
#     tokenizer = AutoTokenizer.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", use_fast=False)
#
#     # Tokenize sentence v√† chuy·ªÉn th√†nh tensor
#     input_ids = torch.tensor([tokenizer.encode(sentence)])
#
#     # Ti·∫øn h√†nh tri·ªÉn khai model v·ªõi input
#     with torch.no_grad():
#         out = model(input_ids)
#         # T√≠nh softmax ƒë·ªÉ ph√¢n lo·∫°i v√† in k·∫øt qu·∫£ c√≥ d·∫°ng [[NEG, POS, NEU]]
#         sentiment_result = out.logits.softmax(dim=-1).tolist()
#         print(sentiment_result)
#         processed_label = rating_sentiment(sentiment_result)
#         return {'label': processed_label, 'sentence': sentence}


# # ƒê∆∞a v√†o m·ªôt ƒë·ªëi t∆∞·ª£ng g·ªìm sentiment: k·∫øt qu·∫£ th·ª±c hi·ªán v√† sentence: c√¢u t∆∞∆°ng ·ª©ng ƒë·ªÉ th·ª±c hi·ªán
# def perform_sentiment_analysis(input_data):
#     # N·∫øu kh√¥ng c√≥ sentence
#     if input_data['sentence'] is None: return None
#     # N·∫øu ƒë√£ c√≥ sentiment v√† sentence (Kh√¥ng c·∫ßn th·ª±c hi·ªán n·ªØa)
#     if input_data['sentiment'] is not None and input_data['sentence'] is not None: return input_data
#     pre_process_sentence = pre_processing_data(input_data['sentence'])
#     return perform_model(pre_process_sentence)


# if __name__ == '__main__':
#     example = {'sentiment': None, 'sentence': 'Nh√† n√†y r·∫•t ·ªïn, d·ªãch v·ª• r·∫•t ch·∫•t l∆∞·ª£ng nh∆∞ng b·ªØa s√°ng h∆°i t·ªá'}
#     result = perform_sentiment_analysis(example)
#     print(result)
