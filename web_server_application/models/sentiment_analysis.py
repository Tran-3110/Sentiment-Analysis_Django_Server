import dotenv, os
import torch, py_vncorenlp
from transformers import RobertaForSequenceClassification, AutoTokenizer

dotenv.load_dotenv()

# Singleton class
class Singleton(type):
    _instances = {}

    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)
        return cls._instances[cls]


# Implement Singleton báº±ng cÃ¡ch dÃ¹ng metaclass
class SentimentAnalysis(metaclass=Singleton):
    def __init__(self):
        self.segmenter = py_vncorenlp.VnCoreNLP(annotators=["wseg"], save_dir=os.getenv('VN_CORE_NLP_PATH'))
        self.model = RobertaForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment")
        self.tokenizer = AutoTokenizer.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", use_fast=False)

    def __pre_processing_data(self, sentence):
        output = self.segmenter.word_segment(sentence)  # Xá»­ lÃ½ vÄƒn báº£n
        # Join cÃ¡c tá»« trong list Ä‘á»ƒ merge láº¡i
        return ''.join([word for word in output])

    def __perform_model(self, input_data):
        # Táº£i model
        # Khai bÃ¡o option cache_dir dÃ¹ng Ä‘á»ƒ lÆ°u model vÃ o thÆ° má»¥c chá»‰ Ä‘á»‹nh (Náº·ng 500mb ðŸ¥²ðŸ˜ƒ). Náº¿u khÃ´ng thÃ¬ sáº½ lÆ°u vÃ o cache

        # Táº£i tokenizer (Xem BERT)
        # tokenizer = AutoTokenizer.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", use_fast=False)

        #Tiá»n xá»­ lÃ½
        sentence = self.__pre_processing_data(input_data['sentence'])
        # Tokenize sentence vÃ  chuyá»ƒn thÃ nh tensor
        input_ids = torch.tensor([self.tokenizer.encode(sentence)])

        # Tiáº¿n hÃ nh triá»ƒn khai model vá»›i input
        with torch.no_grad():
            out = self.model(input_ids)
            # TÃ­nh softmax Ä‘á»ƒ phÃ¢n loáº¡i vÃ  in káº¿t quáº£ cÃ³ dáº¡ng [[negative, positive, neutral]]
            sentiment_result = out.logits.softmax(dim=-1).tolist()
            print(sentiment_result)
            processed_label = rating_sentiment(sentiment_result)
            return {'label': processed_label, 'sentence': input_data['sentence']}

    def perform_sentiment_analysis(self, input_data):
        # Náº¿u khÃ´ng cÃ³ sentence
        if input_data['sentence'] == 'None': return None
        # Náº¿u Ä‘Ã£ cÃ³ sentiment vÃ  sentence (KhÃ´ng cáº§n thá»±c hiá»‡n ná»¯a)
        if input_data['sentiment'] != 'None' and input_data['sentence'] != 'None': return input_data
        return self.__perform_model(input_data)


def rating_sentiment(sentiment_result):
    sentiment_output = sentiment_result[0]
    label = ['negative', 'positive', 'neutral']

    # GÃ¡n nhÃ£n vá»›i tá»«ng tá»‰ lá»‡ xuáº¥t hiá»‡n cá»§a tá»«ng loáº¡i cáº£m xÃºc
    sentiment_rating = [{'label': x, 'rate': sentiment_output[label.index(x)] / sum(sentiment_output)} for x in label]
    sentiment_rating.sort(key=lambda x: x['rate'], reverse=True)

    max_rating = sentiment_rating[0]
    mid_rating = sentiment_rating[1]

    # Bá» pháº§n ngÆ°á»¡ng xÃ¡c Ä‘á»‹nh vá»›i cÃ¡c case gáº§n nhau, cho tráº£ vá» trá»±c tiáº¿p label cÃ³ tá»‰ lá»‡ cao nháº¥t
    # if abs(max_rating['rate'] - mid_rating['rate']) > delta:
    #     return 'neutral' if max_rating['label'] == 'neutral' else max_rating['label']
    # else:
    #     if max_rating['label'] != 'neutral' and mid_rating['label'] != 'neutral':
    #         return 'neutral'
    #     else:
    #         return max_rating['label']
    return max_rating['label']
