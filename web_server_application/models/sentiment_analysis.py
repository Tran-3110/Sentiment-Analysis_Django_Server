import dotenv, os
import torch, py_vncorenlp
from transformers import RobertaForSequenceClassification, AutoTokenizer

dotenv.load_dotenv()


def pre_processing_data(sentence):
    # Load VnCoreNLP
    segmenter = py_vncorenlp.VnCoreNLP(annotators=["wseg"], save_dir=os.getenv('VN_CORE_NLP_PATH'))
    output = segmenter.word_segment(sentence)  # X·ª≠ l√Ω vƒÉn b·∫£n
    # Join c√°c t·ª´ trong list ƒë·ªÉ merge l·∫°i
    return ''.join([word for word in output])


def perform_model(sentence):
    # T·∫£i model
    # Khai b√°o option cache_dir d√πng ƒë·ªÉ l∆∞u model v√†o th∆∞ m·ª•c ch·ªâ ƒë·ªãnh (N·∫∑ng 500mb ü•≤üòÉ). N·∫øu kh√¥ng th√¨ s·∫Ω l∆∞u v√†o cache
    # model = RobertaForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", cache_dir='model/model_sa_phobert')

    model = RobertaForSequenceClassification.from_pretrained("wonrax/phobert-base-vietnamese-sentiment")

    # T·∫£i tokenizer (Xem BERT)
    tokenizer = AutoTokenizer.from_pretrained("wonrax/phobert-base-vietnamese-sentiment", use_fast=False)

    # Tokenize sentence v√† chuy·ªÉn th√†nh tensor
    input_ids = torch.tensor([tokenizer.encode(sentence)])

    # Ti·∫øn h√†nh tri·ªÉn khai model v·ªõi input
    with torch.no_grad():
        out = model(input_ids)
        # T√≠nh softmax ƒë·ªÉ ph√¢n lo·∫°i v√† in k·∫øt qu·∫£ c√≥ d·∫°ng [[NEG, POS, NEU]]
        sentiment_result = out.logits.softmax(dim=-1).tolist()
        print(sentiment_result)
        processed_label = rating_sentiment(sentiment_result)
        return {'label': processed_label, 'sentence': sentence}


def rating_sentiment(sentiment_result, delta=0.15):
    sentiment_output = sentiment_result[0]
    label = ['NEG', 'POS', 'NEU']

    # G√°n nh√£n v·ªõi t·ª´ng t·ªâ l·ªá xu·∫•t hi·ªán c·ªßa t·ª´ng lo·∫°i c·∫£m x√∫c
    sentiment_rating = [{'label': x, 'rate': sentiment_output[label.index(x)] / sum(sentiment_output)} for x in label]
    sentiment_rating.sort(key=lambda x: x['rate'], reverse=True)

    max_rating = sentiment_rating[0]
    mid_rating = sentiment_rating[1]

    if abs(max_rating['rate'] - mid_rating['rate']) > delta:
        return 'NEU' if max_rating['label'] == 'NEU' else max_rating['label']
    else:
        if max_rating['label'] != 'NEU' and mid_rating['label'] != 'NEU':
            return 'NEU'
        else:
            return max_rating['label']
    # return max(sentiment_rating, key=lambda x: x['rate'])['label']


# ƒê∆∞a v√†o m·ªôt ƒë·ªëi t∆∞·ª£ng g·ªìm sentiment: k·∫øt qu·∫£ th·ª±c hi·ªán v√† sentence: c√¢u t∆∞∆°ng ·ª©ng ƒë·ªÉ th·ª±c hi·ªán
def perform_sentiment_analysis(input_data):
    # N·∫øu kh√¥ng c√≥ sentence
    if input_data['sentence'] is None: return None
    # N·∫øu ƒë√£ c√≥ sentiment v√† sentence (Kh√¥ng c·∫ßn th·ª±c hi·ªán n·ªØa)
    if input_data['sentiment'] is not None and input_data['sentence'] is not None: return input_data
    pre_process_sentence = pre_processing_data(input_data['sentence'])
    return perform_model(pre_process_sentence)


if __name__ == '__main__':
    example = {'sentiment': None, 'sentence': 'Nh√† n√†y r·∫•t ·ªïn, d·ªãch v·ª• r·∫•t ch·∫•t l∆∞·ª£ng nh∆∞ng b·ªØa s√°ng h∆°i t·ªá'}
    result = perform_sentiment_analysis(example)
    print(result)
